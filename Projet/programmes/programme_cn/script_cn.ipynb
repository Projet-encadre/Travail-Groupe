{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea28c3aa-2a48-47aa-b8a2-e5cc29cda20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b73f46-c285-467f-9477-656d607a1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chinese_text(\n",
    "    folder_path,       # 文本文档所在的文件夹\n",
    "    keyword=\"根\",       # 要搜索的关键词\n",
    "    context_chars=20,  # 字符上下文窗口大小\n",
    "    out_folder=\"context\",  # 保存上下文的输出文件夹\n",
    "    max_files=20       # 处理的文本文档数量（cn-1 到 cn-20）\n",
    "):\n",
    "    \"\"\"\n",
    "    统计每个文本文档的字数，关键词出现次数，并提取上下文。\n",
    "    \"\"\"\n",
    "    # 如果输出文件夹不存在，则创建\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # 结果统计\n",
    "    stats = []\n",
    "\n",
    "    for i in range(1, max_files + 1):\n",
    "        filename = f\"cn-{i}.txt\"\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"文件 {filename} 不存在，跳过。\")\n",
    "            continue\n",
    "\n",
    "        # 读取文件内容，假设文件为 UTF-8 编码\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # 统计字数（中文文本中的每个字符计为一个字）\n",
    "        total_chars = len(text)\n",
    "\n",
    "        # 统计关键词出现次数\n",
    "        keyword_count = len(re.findall(re.escape(keyword), text))\n",
    "\n",
    "        # 提取关键词的上下文\n",
    "        context_snippets = []\n",
    "        for match in re.finditer(re.escape(keyword), text):\n",
    "            start_idx = max(0, match.start() - context_chars)\n",
    "            end_idx = min(len(text), match.end() + context_chars)\n",
    "            snippet = text[start_idx:end_idx]\n",
    "            context_snippets.append(snippet)\n",
    "\n",
    "        # 保存上下文到文件\n",
    "        output_file = os.path.join(out_folder, f\"context-cn-{i}.txt\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "            if not context_snippets:\n",
    "                out_f.write(\"未找到关键词的上下文。\\n\")\n",
    "            else:\n",
    "                for snippet in context_snippets:\n",
    "                    out_f.write(snippet.replace(\"\\n\", \" \") + \"\\n\")\n",
    "\n",
    "        # 保存统计信息\n",
    "        stats.append({\n",
    "            \"file\": filename,\n",
    "            \"total_chars\": total_chars,\n",
    "            \"keyword_count\": keyword_count,\n",
    "            \"output_file\": output_file\n",
    "        })\n",
    "\n",
    "    # 输出统计结果\n",
    "    print(f\"{'文件名':<15}{'字数':<10}{'关键词次数':<10}{'上下文文件':<20}\")\n",
    "    print(\"-\" * 60)\n",
    "    for stat in stats:\n",
    "        print(f\"{stat['file']:<15}{stat['total_chars']:<10}{stat['keyword_count']:<10}{stat['output_file']:<20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa9f6a6-2a6c-4eca-a4de-a6d6cefda27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件名            字数        关键词次数     上下文文件               \n",
      "------------------------------------------------------------\n",
      "cn-1.txt       12793     202       context/context-cn-1.txt\n",
      "cn-2.txt       7225      7         context/context-cn-2.txt\n",
      "cn-3.txt       68533     60        context/context-cn-3.txt\n",
      "cn-4.txt       1382      27        context/context-cn-4.txt\n",
      "cn-5.txt       2079      49        context/context-cn-5.txt\n",
      "cn-6.txt       9911      21        context/context-cn-6.txt\n",
      "cn-7.txt       1429      48        context/context-cn-7.txt\n",
      "cn-8.txt       1771      65        context/context-cn-8.txt\n",
      "cn-9.txt       917       4         context/context-cn-9.txt\n",
      "cn-10.txt      2734      12        context/context-cn-10.txt\n",
      "cn-11.txt      2205      34        context/context-cn-11.txt\n",
      "cn-12.txt      3484      61        context/context-cn-12.txt\n",
      "cn-13.txt      4595      25        context/context-cn-13.txt\n",
      "cn-14.txt      2599      22        context/context-cn-14.txt\n",
      "cn-15.txt      20234     76        context/context-cn-15.txt\n",
      "cn-16.txt      11325     34        context/context-cn-16.txt\n",
      "cn-17.txt      9337      340       context/context-cn-17.txt\n",
      "cn-18.txt      3747      53        context/context-cn-18.txt\n",
      "cn-19.txt      1441      39        context/context-cn-19.txt\n",
      "cn-20.txt      8787      25        context/context-cn-20.txt\n"
     ]
    }
   ],
   "source": [
    "source_folder = \"./dumps-text\"  # 文件夹路径 (当前文件夹为例)\n",
    "process_chinese_text(\n",
    "    folder_path=source_folder,\n",
    "    keyword=\"根\",          # 要统计的关键词\n",
    "    context_chars=20,      # 上下文字符窗口大小\n",
    "    out_folder=\"context\",  # 保存上下文的文件夹\n",
    "    max_files=20           # 要处理的文本文档数量\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
